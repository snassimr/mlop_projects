#---------------STEP 1 Environment Setup----------------#
FROM google/cloud-sdk:latest

RUN apt-get update 
RUN apt-get install -y python3
RUN mkdir /kubeflow_practice

COPY requirements.txt /kubeflow_practice

RUN mkdir /src
COPY read_data.py /kubeflow_practice/src

RUN pip install -r /kubeflow_practice/requirements.txt

#---------------STEP 2 Call the process---------------#
ENTRYPOINT [ "python3","/kubeflow_practice/read_data.py" ]

#---------------STEP 3 Create image in Docker Registry or Google Artifact Registry---------------#

#docker build -t read_data -f Dockerfile .
#docker run syntax
#docker run -v local_dir:/mounted_dir read_data --data_path=mounted_dir/data/train_MpHjUjU.csv
#link local docker image to revised image name as per GCP specifications
#docker tag load_data us-docker.pkg.dev/steady-cat-331605/gcr.io/read_data:1.0
#authorization command to be able to push to AR
#gcloud auth configure-docker us-docker.pkg.dev
#docker push to google cloud artifact registry
#docker push us-docker.pkg.dev/steady-cat-331605/gcr.io/read_data:1.0